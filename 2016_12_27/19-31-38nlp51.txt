3a4,13
> 
> From
> Wikipedia,
> the
> free
> encyclopedia
> 
> Natural
> language
> processing
37a48,77
> Many
> challenges
> in
> NLP
> involve
> natural
> language
> understanding,
> that
> is,
> enabling
> computers
> to
> derive
> meaning
> from
> human
> or
> natural
> language
> input,
> and
> others
> involve
> natural
> language
> generation.
> 
> History
> 
55a96,122
> In
> 1950,
> Alan
> Turing
> published
> an
> article
> titled
> "Computing
> Machinery
> and
> Intelligence"
> which
> proposed
> what
> is
> now
> called
> the
> Turing
> test
> as
> a
> criterion
> of
> intelligence.
> 
124a192,213
> Little
> further
> research
> in
> machine
> translation
> was
> conducted
> until
> the
> late
> 1980s,
> when
> the
> first
> statistical
> machine
> translation
> systems
> were
> developed.
> 
181a271,301
> When
> the
> "patient"
> exceeded
> the
> very
> small
> knowledge
> base,
> ELIZA
> might
> provide
> a
> generic
> response,
> for
> example,
> responding
> to
> "My
> head
> hurts"
> with
> "Why
> do
> you
> say
> your
> head
> hurts?".
> 
225a346,358
> During
> this
> time,
> many
> chatterbots
> were
> written
> including
> PARRY,
> Racter,
> and
> Jabberwacky.
> 
395a529,565
> Such
> models
> are
> generally
> more
> robust
> when
> given
> unfamiliar
> input,
> especially
> input
> that
> contains
> errors
> (as
> is
> very
> common
> for
> real-world
> data),
> and
> produce
> more
> reliable
> results
> when
> integrated
> into
> a
> larger
> system
> comprising
> multiple
> subtasks.
> 
506a677,698
> As
> a
> result,
> a
> great
> deal
> of
> research
> has
> gone
> into
> methods
> of
> more
> effectively
> learning
> from
> limited
> amounts
> of
> data.
> 
569a762,798
> However,
> there
> is
> an
> enormous
> amount
> of
> non-annotated
> data
> available
> (including,
> among
> other
> things,
> the
> entire
> content
> of
> the
> World
> Wide
> Web),
> which
> can
> often
> make
> up
> for
> the
> inferior
> results.
> 
> NLP
> using
> machine
> learning
> 
652a882,906
> A
> corpus
> (plural,
> "corpora")
> is
> a
> set
> of
> documents
> (or
> sometimes,
> individual
> sentences)
> that
> have
> been
> hand-annotated
> with
> the
> correct
> values
> to
> be
> learned.
> 
734a989,1073
> Such
> models
> have
> the
> advantage
> that
> they
> can
> express
> the
> relative
> certainty
> of
> many
> different
> possible
> answers
> rather
> than
> only
> one,
> producing
> more
> reliable
> results
> when
> such
> a
> model
> is
> included
> as
> a
> component
> of
> a
> larger
> system.
> 
> Systems
> based
> on
> machine-learning
> algorithms
> have
> many
> advantages
> over
> hand-produced
> rules:
> 
> The
> learning
> procedures
> used
> during
> machine
> learning
> automatically
> focus
> on
> the
> most
> common
> cases,
> whereas
> when
> writing
> rules
> by
> hand
> it
> is
> often
> not
> obvious
> at
> all
> where
> the
> effort
> should
> be
> directed.
> 
777a1117,1144
> Generally,
> handling
> such
> input
> gracefully
> with
> hand-written
> rules
> --
> or
> more
> generally,
> creating
> systems
> of
> hand-written
> rules
> that
> make
> soft
> decisions
> --
> extremely
> difficult,
> error-prone
> and
> time-consuming.
> 
848a1216,1247
> However,
> creating
> more
> data
> to
> input
> to
> machine-learning
> systems
> simply
> requires
> a
> corresponding
> increase
> in
> the
> number
> of
> man-hours
> worked,
> generally
> without
> significant
> increases
> in
> the
> complexity
> of
> the
> annotation
> process.
> 
886a1286,1313
> When
> the
> aims
> of
> computational
> language
> learning
> research
> is
> to
> understand
> more
> about
> human
> language
> acquisition,
> or
> psycholinguistics,
> NLL
> overlaps
> into
> the
> related
> field
> of
> Computational
> Psycholinguistics.
> 
